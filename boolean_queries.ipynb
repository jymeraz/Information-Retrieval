{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porter Stemmer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"Porter Stemming Algorithm\n",
    "This is the Porter stemming algorithm, ported to Python from the\n",
    "version coded up in ANSI C by the author. It may be be regarded\n",
    "as canonical, in that it follows the algorithm presented in\n",
    "\n",
    "Porter, 1980, An algorithm for suffix stripping, Program, Vol. 14,\n",
    "no. 3, pp 130-137,\n",
    "\n",
    "only differing from it at the points maked --DEPARTURE-- below.\n",
    "\n",
    "See also http://www.tartarus.org/~martin/PorterStemmer\n",
    "\n",
    "The algorithm as described in the paper could be exactly replicated\n",
    "by adjusting the points of DEPARTURE, but this is barely necessary,\n",
    "because (a) the points of DEPARTURE are definitely improvements, and\n",
    "(b) no encoding of the Porter stemmer I have seen is anything like\n",
    "as exact as this version, even with the points of DEPARTURE!\n",
    "\n",
    "Vivake Gupta (v@nano.com)\n",
    "\n",
    "Release 1: January 2001\n",
    "\n",
    "Further adjustments by Santiago Bruno (bananabruno@gmail.com)\n",
    "to allow word input not restricted to one word per line, leading\n",
    "to:\n",
    "\n",
    "release 2: July 2008\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "class PorterStemmer:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"The main part of the stemming algorithm starts here.\n",
    "        b is a buffer holding a word to be stemmed. The letters are in b[k0],\n",
    "        b[k0+1] ... ending at b[k]. In fact k0 = 0 in this demo program. k is\n",
    "        readjusted downwards as the stemming progresses. Zero termination is\n",
    "        not in fact used in the algorithm.\n",
    "\n",
    "        Note that only lower case sequences are stemmed. Forcing to lower case\n",
    "        should be done before stem(...) is called.\n",
    "        \"\"\"\n",
    "\n",
    "        self.b = \"\"  # buffer for word to be stemmed\n",
    "        self.k = 0\n",
    "        self.k0 = 0\n",
    "        self.j = 0   # j is a general offset into the string\n",
    "\n",
    "    def cons(self, i):\n",
    "        \"\"\"cons(i) is TRUE <=> b[i] is a consonant.\"\"\"\n",
    "        if self.b[i] == 'a' or self.b[i] == 'e' or self.b[i] == 'i' or self.b[i] == 'o' or self.b[i] == 'u':\n",
    "            return 0\n",
    "        if self.b[i] == 'y':\n",
    "            if i == self.k0:\n",
    "                return 1\n",
    "            else:\n",
    "                return (not self.cons(i - 1))\n",
    "        return 1\n",
    "\n",
    "    def m(self):\n",
    "        \"\"\"m() measures the number of consonant sequences between k0 and j.\n",
    "        if c is a consonant sequence and v a vowel sequence, and <..>\n",
    "        indicates arbitrary presence,\n",
    "\n",
    "           <c><v>       gives 0\n",
    "           <c>vc<v>     gives 1\n",
    "           <c>vcvc<v>   gives 2\n",
    "           <c>vcvcvc<v> gives 3\n",
    "           ....\n",
    "        \"\"\"\n",
    "        n = 0\n",
    "        i = self.k0\n",
    "        while 1:\n",
    "            if i > self.j:\n",
    "                return n\n",
    "            if not self.cons(i):\n",
    "                break\n",
    "            i = i + 1\n",
    "        i = i + 1\n",
    "        while 1:\n",
    "            while 1:\n",
    "                if i > self.j:\n",
    "                    return n\n",
    "                if self.cons(i):\n",
    "                    break\n",
    "                i = i + 1\n",
    "            i = i + 1\n",
    "            n = n + 1\n",
    "            while 1:\n",
    "                if i > self.j:\n",
    "                    return n\n",
    "                if not self.cons(i):\n",
    "                    break\n",
    "                i = i + 1\n",
    "            i = i + 1\n",
    "\n",
    "    def vowelinstem(self):\n",
    "        \"\"\"vowelinstem() is TRUE <=> k0,...j contains a vowel\"\"\"\n",
    "        for i in range(self.k0, self.j + 1):\n",
    "            if not self.cons(i):\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def doublec(self, j):\n",
    "        \"\"\"doublec(j) is TRUE <=> j,(j-1) contain a double consonant.\"\"\"\n",
    "        if j < (self.k0 + 1):\n",
    "            return 0\n",
    "        if (self.b[j] != self.b[j-1]):\n",
    "            return 0\n",
    "        return self.cons(j)\n",
    "\n",
    "    def cvc(self, i):\n",
    "        \"\"\"cvc(i) is TRUE <=> i-2,i-1,i has the form consonant - vowel - consonant\n",
    "        and also if the second c is not w,x or y. this is used when trying to\n",
    "        restore an e at the end of a short  e.g.\n",
    "\n",
    "           cav(e), lov(e), hop(e), crim(e), but\n",
    "           snow, box, tray.\n",
    "        \"\"\"\n",
    "        if i < (self.k0 + 2) or not self.cons(i) or self.cons(i-1) or not self.cons(i-2):\n",
    "            return 0\n",
    "        ch = self.b[i]\n",
    "        if ch == 'w' or ch == 'x' or ch == 'y':\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    def ends(self, s):\n",
    "        \"\"\"ends(s) is TRUE <=> k0,...k ends with the string s.\"\"\"\n",
    "        length = len(s)\n",
    "        if s[length - 1] != self.b[self.k]: # tiny speed-up\n",
    "            return 0\n",
    "        if length > (self.k - self.k0 + 1):\n",
    "            return 0\n",
    "        if self.b[self.k-length+1:self.k+1] != s:\n",
    "            return 0\n",
    "        self.j = self.k - length\n",
    "        return 1\n",
    "\n",
    "    def setto(self, s):\n",
    "        \"\"\"setto(s) sets (j+1),...k to the characters in the string s, readjusting k.\"\"\"\n",
    "        length = len(s)\n",
    "        self.b = self.b[:self.j+1] + s + self.b[self.j+length+1:]\n",
    "        self.k = self.j + length\n",
    "\n",
    "    def r(self, s):\n",
    "        \"\"\"r(s) is used further down.\"\"\"\n",
    "        if self.m() > 0:\n",
    "            self.setto(s)\n",
    "\n",
    "    def step1ab(self):\n",
    "        \"\"\"step1ab() gets rid of plurals and -ed or -ing. e.g.\n",
    "\n",
    "           caresses  ->  caress\n",
    "           ponies    ->  poni\n",
    "           ties      ->  ti\n",
    "           caress    ->  caress\n",
    "           cats      ->  cat\n",
    "\n",
    "           feed      ->  feed\n",
    "           agreed    ->  agree\n",
    "           disabled  ->  disable\n",
    "\n",
    "           matting   ->  mat\n",
    "           mating    ->  mate\n",
    "           meeting   ->  meet\n",
    "           milling   ->  mill\n",
    "           messing   ->  mess\n",
    "\n",
    "           meetings  ->  meet\n",
    "        \"\"\"\n",
    "        if self.b[self.k] == 's':\n",
    "            if self.ends(\"sses\"):\n",
    "                self.k = self.k - 2\n",
    "            elif self.ends(\"ies\"):\n",
    "                self.setto(\"i\")\n",
    "            elif self.b[self.k - 1] != 's':\n",
    "                self.k = self.k - 1\n",
    "        if self.ends(\"eed\"):\n",
    "            if self.m() > 0:\n",
    "                self.k = self.k - 1\n",
    "        elif (self.ends(\"ed\") or self.ends(\"ing\")) and self.vowelinstem():\n",
    "            self.k = self.j\n",
    "            if self.ends(\"at\"):   self.setto(\"ate\")\n",
    "            elif self.ends(\"bl\"): self.setto(\"ble\")\n",
    "            elif self.ends(\"iz\"): self.setto(\"ize\")\n",
    "            elif self.doublec(self.k):\n",
    "                self.k = self.k - 1\n",
    "                ch = self.b[self.k]\n",
    "                if ch == 'l' or ch == 's' or ch == 'z':\n",
    "                    self.k = self.k + 1\n",
    "            elif (self.m() == 1 and self.cvc(self.k)):\n",
    "                self.setto(\"e\")\n",
    "\n",
    "    def step1c(self):\n",
    "        \"\"\"step1c() turns terminal y to i when there is another vowel in the stem.\"\"\"\n",
    "        if (self.ends(\"y\") and self.vowelinstem()):\n",
    "            self.b = self.b[:self.k] + 'i' + self.b[self.k+1:]\n",
    "\n",
    "    def step2(self):\n",
    "        \"\"\"step2() maps double suffices to single ones.\n",
    "        so -ization ( = -ize plus -ation) maps to -ize etc. note that the\n",
    "        string before the suffix must give m() > 0.\n",
    "        \"\"\"\n",
    "        if self.b[self.k - 1] == 'a':\n",
    "            if self.ends(\"ational\"):   self.r(\"ate\")\n",
    "            elif self.ends(\"tional\"):  self.r(\"tion\")\n",
    "        elif self.b[self.k - 1] == 'c':\n",
    "            if self.ends(\"enci\"):      self.r(\"ence\")\n",
    "            elif self.ends(\"anci\"):    self.r(\"ance\")\n",
    "        elif self.b[self.k - 1] == 'e':\n",
    "            if self.ends(\"izer\"):      self.r(\"ize\")\n",
    "        elif self.b[self.k - 1] == 'l':\n",
    "            if self.ends(\"bli\"):       self.r(\"ble\") # --DEPARTURE--\n",
    "            # To match the published algorithm, replace this phrase with\n",
    "            #   if self.ends(\"abli\"):      self.r(\"able\")\n",
    "            elif self.ends(\"alli\"):    self.r(\"al\")\n",
    "            elif self.ends(\"entli\"):   self.r(\"ent\")\n",
    "            elif self.ends(\"eli\"):     self.r(\"e\")\n",
    "            elif self.ends(\"ousli\"):   self.r(\"ous\")\n",
    "        elif self.b[self.k - 1] == 'o':\n",
    "            if self.ends(\"ization\"):   self.r(\"ize\")\n",
    "            elif self.ends(\"ation\"):   self.r(\"ate\")\n",
    "            elif self.ends(\"ator\"):    self.r(\"ate\")\n",
    "        elif self.b[self.k - 1] == 's':\n",
    "            if self.ends(\"alism\"):     self.r(\"al\")\n",
    "            elif self.ends(\"iveness\"): self.r(\"ive\")\n",
    "            elif self.ends(\"fulness\"): self.r(\"ful\")\n",
    "            elif self.ends(\"ousness\"): self.r(\"ous\")\n",
    "        elif self.b[self.k - 1] == 't':\n",
    "            if self.ends(\"aliti\"):     self.r(\"al\")\n",
    "            elif self.ends(\"iviti\"):   self.r(\"ive\")\n",
    "            elif self.ends(\"biliti\"):  self.r(\"ble\")\n",
    "        elif self.b[self.k - 1] == 'g': # --DEPARTURE--\n",
    "            if self.ends(\"logi\"):      self.r(\"log\")\n",
    "        # To match the published algorithm, delete this phrase\n",
    "\n",
    "    def step3(self):\n",
    "        \"\"\"step3() dels with -ic-, -full, -ness etc. similar strategy to step2.\"\"\"\n",
    "        if self.b[self.k] == 'e':\n",
    "            if self.ends(\"icate\"):     self.r(\"ic\")\n",
    "            elif self.ends(\"ative\"):   self.r(\"\")\n",
    "            elif self.ends(\"alize\"):   self.r(\"al\")\n",
    "        elif self.b[self.k] == 'i':\n",
    "            if self.ends(\"iciti\"):     self.r(\"ic\")\n",
    "        elif self.b[self.k] == 'l':\n",
    "            if self.ends(\"ical\"):      self.r(\"ic\")\n",
    "            elif self.ends(\"ful\"):     self.r(\"\")\n",
    "        elif self.b[self.k] == 's':\n",
    "            if self.ends(\"ness\"):      self.r(\"\")\n",
    "\n",
    "    def step4(self):\n",
    "        \"\"\"step4() takes off -ant, -ence etc., in context <c>vcvc<v>.\"\"\"\n",
    "        if self.b[self.k - 1] == 'a':\n",
    "            if self.ends(\"al\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'c':\n",
    "            if self.ends(\"ance\"): pass\n",
    "            elif self.ends(\"ence\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'e':\n",
    "            if self.ends(\"er\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'i':\n",
    "            if self.ends(\"ic\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'l':\n",
    "            if self.ends(\"able\"): pass\n",
    "            elif self.ends(\"ible\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'n':\n",
    "            if self.ends(\"ant\"): pass\n",
    "            elif self.ends(\"ement\"): pass\n",
    "            elif self.ends(\"ment\"): pass\n",
    "            elif self.ends(\"ent\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'o':\n",
    "            if self.ends(\"ion\") and (self.b[self.j] == 's' or self.b[self.j] == 't'): pass\n",
    "            elif self.ends(\"ou\"): pass\n",
    "            # takes care of -ous\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 's':\n",
    "            if self.ends(\"ism\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 't':\n",
    "            if self.ends(\"ate\"): pass\n",
    "            elif self.ends(\"iti\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'u':\n",
    "            if self.ends(\"ous\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'v':\n",
    "            if self.ends(\"ive\"): pass\n",
    "            else: return\n",
    "        elif self.b[self.k - 1] == 'z':\n",
    "            if self.ends(\"ize\"): pass\n",
    "            else: return\n",
    "        else:\n",
    "            return\n",
    "        if self.m() > 1:\n",
    "            self.k = self.j\n",
    "\n",
    "    def step5(self):\n",
    "        \"\"\"step5() removes a final -e if m() > 1, and changes -ll to -l if\n",
    "        m() > 1.\n",
    "        \"\"\"\n",
    "        self.j = self.k\n",
    "        if self.b[self.k] == 'e':\n",
    "            a = self.m()\n",
    "            if a > 1 or (a == 1 and not self.cvc(self.k-1)):\n",
    "                self.k = self.k - 1\n",
    "        if self.b[self.k] == 'l' and self.doublec(self.k) and self.m() > 1:\n",
    "            self.k = self.k -1\n",
    "\n",
    "    def stem(self, p, i, j):\n",
    "        \"\"\"In stem(p,i,j), p is a char pointer, and the string to be stemmed\n",
    "        is from p[i] to p[j] inclusive. Typically i is zero and j is the\n",
    "        offset to the last character of a string, (p[j+1] == '\\0'). The\n",
    "        stemmer adjusts the characters p[i] ... p[j] and returns the new\n",
    "        end-point of the string, k. Stemming never increases word length, so\n",
    "        i <= k <= j. To turn the stemmer into a module, declare 'stem' as\n",
    "        extern, and delete the remainder of this file.\n",
    "        \"\"\"\n",
    "        # copy the parameters into statics\n",
    "        self.b = p\n",
    "        self.k = j\n",
    "        self.k0 = i\n",
    "        if self.k <= self.k0 + 1:\n",
    "            return self.b # --DEPARTURE--\n",
    "\n",
    "        # With this line, strings of length 1 or 2 don't go through the\n",
    "        # stemming process, although no mention is made of this in the\n",
    "        # published algorithm. Remove the line to match the published\n",
    "        # algorithm.\n",
    "\n",
    "        self.step1ab()\n",
    "        self.step1c()\n",
    "        self.step2()\n",
    "        self.step3()\n",
    "        self.step4()\n",
    "        self.step5()\n",
    "        return self.b[self.k0:self.k+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Porter Stemmer on a file.\n",
    "# Use the implementation given of stemming given a file.\n",
    "# Apply stemming to all the terms in the file.\n",
    "# Return a string containing all the stemmed terms of the file. \n",
    "def stemmingFile(file):\n",
    "    p = PorterStemmer()\n",
    "    if len(sys.argv) > 1:\n",
    "        for f in sys.argv[1:]:\n",
    "            infile = open(file, 'r')\n",
    "            while 1:\n",
    "                output = ''\n",
    "                word = ''\n",
    "                line = infile.readline()\n",
    "                if line == '':\n",
    "                    break\n",
    "                for c in line:\n",
    "                    if c.isalpha():\n",
    "                        word += c.lower()\n",
    "                    else:\n",
    "                        if word:\n",
    "                            output += p.stem(word, 0,len(word)-1)\n",
    "                            word = ''\n",
    "                        output += c.lower()\n",
    "                return output\n",
    "            infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use and apply the Porter Stemmer on a single term.\n",
    "# Only include the given implementation of stemming a single word.\n",
    "# Return a string the stemmed version of the inputted term.\n",
    "def stemmingWord(wordInput):\n",
    "    p = PorterStemmer()\n",
    "    word = ''\n",
    "    output = ''\n",
    "    for c in wordInput:\n",
    "        if c.isalpha():\n",
    "            word += c.lower()\n",
    "        else:\n",
    "            if word:\n",
    "                output += p.stem(word, 0,len(word)-1)\n",
    "                word = ''\n",
    "            output += c.lower()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two postings list in the event of an \"OR\" search.\n",
    "# If both lists are empty, return -1.\n",
    "# If either list is empty, return the list that is not empty.\n",
    "# Iterate through both lists and add each document to the result.\n",
    "def merge(word1, word2):\n",
    "    if not word1 in dictionary and not word2 in dictionary:\n",
    "        return -1\n",
    "    elif not word1 in dictionary:\n",
    "        return dictionary[word2]\n",
    "    elif not word2 in dictionary:\n",
    "        return dictionary[word1]\n",
    "    result = []\n",
    "    # Save the postings list and initialize iterators for each list.\n",
    "    p1,p2 = dictionary[word1],dictionary[word2]\n",
    "    i,j = 0,0\n",
    "    # Iterate through both lists.\n",
    "    # Add each document in ascending order to the result.\n",
    "    while i < len(p1) and j < len(p2):\n",
    "        if int(p1[i][1]) == int(p2[j][1]):\n",
    "            result += [p1[i]] \n",
    "            i+=1\n",
    "            j+=1\n",
    "        elif int(p1[i][1]) < int(p2[j][1]):\n",
    "            result += [p1[i]] \n",
    "            i+=1\n",
    "        else:\n",
    "            result += [p2[j]] \n",
    "            j+=1\n",
    "    # If one iterator reached the end of the list, concatenate the rest of the other list to the result.\n",
    "    if i < len(p1):\n",
    "        result += p1[i:]\n",
    "    elif j < len(p2):\n",
    "        result += p2[j:]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the intersection of the two postings list in the event of an \"AND\" search.\n",
    "# If either list is empty, return -1.\n",
    "def intersection(word1, word2):\n",
    "    if not word1 in dictionary or not word2 in dictionary:\n",
    "        return -1\n",
    "    result = []\n",
    "    # Save the postings list and initialize iterators for each list.\n",
    "    p1,p2 = dictionary[word1],dictionary[word2]\n",
    "    i,j = 0,0\n",
    "    # Iterate through both lists.\n",
    "    # Add each document in ascending order that is in both lists to the result.\n",
    "    while i < len(p1) and j < len(p2):\n",
    "        if p1[i] == p2[j]:\n",
    "            result += [p1[i]] \n",
    "            i+=1\n",
    "            j+=1 \n",
    "        elif int(p1[i][1]) < int(p2[j][1]):\n",
    "            i+=1\n",
    "        else:\n",
    "            j+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stemming to each document.\n",
    "# Save the tokenized list of each stemmed document in a variable.\n",
    "# Tokenizing avoids having terms with punctuations.  \n",
    "doc1 = nltk.word_tokenize(stemmingFile('d1.txt'))\n",
    "doc2 = nltk.word_tokenize(stemmingFile('d2.txt'))\n",
    "doc3 = nltk.word_tokenize(stemmingFile('d3.txt'))\n",
    "doc4 = nltk.word_tokenize(stemmingFile('d4.txt'))\n",
    "doc5 = nltk.word_tokenize(stemmingFile('d5.txt'))\n",
    "doc6 = nltk.word_tokenize(stemmingFile('d6.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with all the terms in document one.\n",
    "# Set the value for each term in the dictionary as a list containing 'd1'.\n",
    "dictionary = dict.fromkeys(doc1,['d1'])\n",
    "\n",
    "# Update the dictionary to include the terms in document two. \n",
    "# If the term is already a key in the dictionary, append 'd2' to its value.\n",
    "# If the term is not a key, create a new key with 'd2' as its value.\n",
    "# Update the dictionary to include the terms in the rest of the documents.\n",
    "for i in doc2:\n",
    "    if i in dictionary and not 'd2' in dictionary[i]:\n",
    "        dictionary[i] = dictionary[i] + ['d2']\n",
    "    elif not i in dictionary:\n",
    "        dictionary[i] = ['d2']\n",
    "        \n",
    "for i in doc3:\n",
    "    if i in dictionary and not 'd3' in dictionary[i]:\n",
    "        dictionary[i] = dictionary[i] + ['d3']\n",
    "    elif not i in dictionary:\n",
    "        dictionary[i] = ['d3']\n",
    "        \n",
    "for i in doc4:\n",
    "    if i in dictionary and not 'd4' in dictionary[i]:\n",
    "        dictionary[i] = dictionary[i] + ['d4']\n",
    "    elif not i in dictionary:\n",
    "        dictionary[i] = ['d4']\n",
    "        \n",
    "for i in doc5:\n",
    "    if i in dictionary and not 'd5' in dictionary[i]:\n",
    "        dictionary[i] = dictionary[i] + ['d5']\n",
    "    elif not i in dictionary:\n",
    "        dictionary[i] = ['d5']\n",
    "        \n",
    "for i in doc6:\n",
    "    if i in dictionary and not 'd6' in dictionary[i]:\n",
    "        dictionary[i] = dictionary[i] + ['d6']\n",
    "    elif not i in dictionary:\n",
    "        dictionary[i] = ['d6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a new file to write the inverted index to. \n",
    "# For each key in the dictionary, write the key and its corresponding value to the file.\n",
    "# Close the file once all keys and values have been written. \n",
    "index = open('index_Meraz.txt', 'w')\n",
    "for i in dictionary:\n",
    "    index.write('{}{}\\n'.format(i.ljust(25),', '.join(dictionary[i])))\n",
    "index.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open and read the given queries and save them in a list. \n",
    "with open('query.txt') as f:\n",
    "    queries = [[line.strip()] for line in f]\n",
    "\n",
    "# Iterate through the queries and compute their document IDs.\n",
    "# Open a new file to write the results of each query.\n",
    "# Apply stemming to each term in the query.\n",
    "# For queries using \"OR\", merge the two postings list of each term.\n",
    "# For queries using \"AND\", compute the intersection of each term's postings list.\n",
    "# Write the result to a file. \n",
    "file = open('answer.txt', 'w')\n",
    "for i in queries:\n",
    "    word1 = i[0].split()[0]\n",
    "    word2 = i[0].split()[2]\n",
    "    key = i[0].split()[1]\n",
    "    if key == \"OR\":\n",
    "        result = merge(stemmingWord(word1+\"\\n\").strip(\"\\n\"),stemmingWord(word2+\"\\n\").strip(\"\\n\"))\n",
    "    elif key == \"AND\":\n",
    "        result = intersection(stemmingWord(word1+\"\\n\").strip(\"\\n\"),stemmingWord(word2+\"\\n\").strip(\"\\n\"))\n",
    "    # Set the overall result of the query to -1.\n",
    "    # If the overall result is not -1, convert the resultant list to a string. \n",
    "    docs = -1\n",
    "    if result != -1:\n",
    "        docs = ', '.join(result)\n",
    "    # Write the query and result to a file. \n",
    "    file.write('{}{}\\n'.format(i[0].ljust(30),docs))\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
